@TechReport{MMAHT2018,
  author={Pablo Montero-Manso and George Athanasopoulos and Rob J Hyndman and Thiyanga S Talagala},
  title={{FFORMA: Feature-based forecast model averaging}},
  year=2018,
  month=,
  institution={Monash University, Department of Econometrics and Business Statistics},
  type={Monash Econometrics and Business Statistics Working Papers},
  url={https://ideas.repec.org/p/msh/ebswps/2018-19.html},
  number={19/18},
  abstract={We propose an automated method for obtaining weighted forecast combinations using time series features. The proposed approach involves two phases. First, we use a collection of time series to train a meta-model to assign weights to various possible forecasting methods with the goal of minimizing the average forecasting loss obtained from a weighted forecast combination. The inputs to the meta-model are features extracted from each series. In the second phase, we forecast new series using a weighted forecast combination where the weights are obtained from our previously trained meta-model. Our method outperforms a simple forecast combination, and outperforms all of the most popular individual methods in the time series forecasting literature. The approach achieved second position in the M4 competition.},
  keywords={time series feature; forecast combination; XGBoost; M4 competition; meta-learning.},
  doi={},
}
@article{SW2009,
author = {Smith, Jeremy and Wallis, Kenneth F.},
year = {2009},
title = {A Simple Explanation of the Forecast Combination Puzzle},
journal = {Oxford Bulletin of Economics and Statistics},
volume = {71},
number = {3},
pages = {331-355}
}
@article{BG69,
 ISSN = {14732858},
 URL = {http://www.jstor.org/stable/3008764},
 abstract = {Two separate sets of forecasts of airline passenger data have been combined to form a composite set of forecasts. The main conclusion is that the composite set of forecasts can yield lower mean-square error than either of the original forecasts. Past errors of each of the original forecasts are used to determine the weights to attach to these two original forecasts in forming the combined forecasts, and different methods of deriving these weights are examined.},
 author = {J. M. Bates and C. W. J. Granger},
 journal = {OR},
 number = {4},
 pages = {451--468},
 publisher = {Operational Research Society},
 title = {The Combination of Forecasts},
 volume = {20},
 year = {1969}
}
@inproceedings{CG16,
  title={Xgboost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining},
  pages={785--794},
  year={2016},
  organization={ACM}
}
@article{GKMT2013,
title = "Combining expert forecasts: Can anything beat the simple average?",
journal = "International Journal of Forecasting",
volume = "29",
number = "1",
pages = "108 - 121",
year = "2013",
issn = "0169-2070",
doi = "https://doi.org/10.1016/j.ijforecast.2012.06.004",
url = "http://www.sciencedirect.com/science/article/pii/S016920701200088X",
author = "Véronique Genre and Geoff Kenny and Aidan Meyler and Allan Timmermann",
keywords = "Forecast combination, Forecast evaluation, Multiple model comparisons, Real-time data, Survey of Professional Forecasters",
abstract = "This paper explores the gains from combining expert forecasts from the ECB Survey of Professional Forecasters (SPF). The analysis encompasses combinations based on principal components and trimmed means, performance-based weighting, and least squares estimates of optimal weights, as well as Bayesian shrinkage. For GDP growth and the unemployment rate, only few of the individual forecast combination schemes outperform the simple equally weighted average forecast in a pseudo-out-of-sample analysis, while there is stronger evidence of improvement over this benchmark for the inflation rate. Nonetheless, when we account for the effect of multiple model comparisons through White’s reality check, the results caution against any assumption that the improvements identified would persist in the future."
}
@article{aiolfi2006persistence,
  title={Persistence in forecasting performance and conditional combination strategies},
  author={Aiolfi, Marco and Timmermann, Allan},
  journal={Journal of Econometrics},
  volume={135},
  number={1-2},
  pages={31--53},
  year={2006},
  publisher={Elsevier}
}
@article{clemen1989combining,
  title={Combining forecasts: A review and annotated bibliography},
  author={Clemen, Robert T},
  journal={International journal of forecasting},
  volume={5},
  number={4},
  pages={559--583},
  year={1989},
  publisher={Elsevier}
}
@article{timmermann2006forecast,
  title={Forecast combinations},
  author={Timmermann, Allan},
  journal={Handbook of economic forecasting},
  volume={1},
  pages={135--196},
  year={2006},
  publisher={Elsevier}
}

@article{Friedberg2018LocalLF,
  title={Local Linear Forests},
  author={Rina Friedberg and Julie Tibshirani and Susan Athey and Stefan Wager},
  journal={ArXiv},
  year={2018},
  volume={abs/1807.11408}
}

@ARTICLE{AtheyImbens2019,
       author = {{Athey}, Susan and {Imbens}, Guido},
        title = "{Machine Learning Methods Economists Should Know About}",
      journal = {arXiv e-prints},
     keywords = {Economics - Econometrics, Statistics - Machine Learning},
         year = "2019",
        month = "Mar",
          eid = {arXiv:1903.10075},
        pages = {arXiv:1903.10075},
archivePrefix = {arXiv},
       eprint = {1903.10075},
 primaryClass = {econ.EM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190310075A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{donaldson1996forecast,
  author = {Donaldson, R. Glen and Kamstra, Mark},
  year = {1996},
  title = {Forecast combining with neural networks},
  journal = {Journal of Forecasting},
  publisher = {Wiley Online Library},
  issn = {1099-131X},
  doi = {10.1002/(SICI)1099-131X(199601)15:1<49::AID-FOR604>3.0.CO;2-2},
  volume = {15},
  month = {1},
  pages = {49--61},
  number = {1},
  url = {https://doi.org/10.1002/(SICI)1099-131X(199601)15:1<49::AID-FOR604>3.0.CO;2-2},
  abstract = {This paper investigates the use of Artificial Neural Networks (ANNs) to combine time series forecasts of stock market volatility from the USA, Canada, Japan and the UK. We demonstrate that combining with nonlinear ANNs generally produces forecasts which, on the basis of out-of-sample forecast encompassing tests and mean squared error comparisons, routinely dominate forecasts from traditional linear combining procedures. Superiority of the ANN arises because of its flexibility to account for potentially complex nonlinear relationships not easily captured by traditional linear models.}
}
@article{SW04JoForc,
author = {Stock, James H. and Watson, Mark W.},
title = {Combination forecasts of output growth in a seven-country data set},
journal = {Journal of Forecasting},
volume = {23},
number = {6},
pages = {405-430},
keywords = {macroeconomic forecasting, high-dimensional forecasting, time-varying parameters, forecast pooling},
doi = {10.1002/for.928},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/for.928},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/for.928},
abstract = {Abstract This paper uses forecast combination methods to forecast output growth in a seven-country quarterly economic data set covering 1959–1999, with up to 73 predictors per country. Although the forecasts based on individual predictors are unstable over time and across countries, and on average perform worse than an autoregressive benchmark, the combination forecasts often improve upon autoregressive forecasts. Despite the unstable performance of the constituent forecasts, the most successful combination forecasts, like the mean, are the least sensitive to the recent performance of the individual forecasts. While consistent with other evidence on the success of simple combination forecasts, this finding is difficult to explain using the theory of combination forecasting in a stationary environment. Copyright © 2004 John Wiley \& Sons, Ltd.},
year = {2004}
}
@article{EGT13,
title = "Complete subset regressions with large-dimensional sets of predictors",
journal = "Journal of Economic Dynamics and Control",
volume = "54",
pages = "86 - 110",
year = "2015",
issn = "0165-1889",
doi = "https://doi.org/10.1016/j.jedc.2015.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S0165188915000524",
author = "Graham Elliott and Antonio Gargano and Allan Timmermann",
keywords = "Complete subset regression, Macroeconomic forecasts, Forecast combination, Factor models",
abstract = "We analyze the complete subset regression (CSR) approach of Elliott et al. (2013) in situations with many possible predictor variables. The CSR approach has the computational advantage that it can be applied even when the number of predictors exceeds the sample size. Theoretical results establish that the CSR approach achieves variance reduction and Monte Carlo simulations show that it offers a favorable bias–variance trade-off in the presence of many weak predictor variables. Empirical applications to out-of-sample predictability of U.S. unemployment, GDP growth and inflation show that CSR combinations produce more accurate point forecasts than a dynamic factor approach or univariate regressions that do not exploit the information in the cross-section of predictors."
}
@techreport{THA18,
  title={Meta-learning how to forecast time series},
  author={Talagala, Thiyanga S and Hyndman, Rob J and Athanasopoulos, George and others},
  year={2018},
  institution={Monash University, Department of Econometrics and Business Statistics}
}

@Manual{forecastPackage,
title = {{forecast}: Forecasting functions for time series and
  linear models},
author = {Rob Hyndman and George Athanasopoulos and Christoph
  Bergmeir and Gabriel Caceres and Leanne Chhay and Mitchell
  O'Hara-Wild and Fotios Petropoulos and Slava Razbash and Earo
  Wang and Farah Yasmeen},
year = {2019},
note = {R package version 8.7},
url = {http://pkg.robjhyndman.com/forecast},
}


@article{friedman2002stochastic,
  title={Stochastic gradient boosting},
  author={Friedman, Jerome H},
  journal={Computational Statistics \& Data Analysis},
  volume={38},
  number={4},
  pages={367--378},
  year={2002},
  publisher={Elsevier}
}

@article{autoETS2002,
author = {Hyndman, Rob and Koehler, Anne and Snyder, Ralph and Grose, Simone},
year = {2002},
month = {02},
pages = {439-454},
title = {A State Space Framework for Automatic Forecasting Using Exponential Smoothing Methods},
volume = {18},
journal = {International Journal of Forecasting},
doi = {10.1016/S0169-2070(01)00110-8}
}

@article{tbats2008,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/23239555},
 abstract = {An innovations state space modeling framework is introduced for forecasting complex seasonal time series such as those with multiple seasonal periods, high-frequency seasonality, non-integer seasonality, and dual-calendar effects. The new framework incorporates Box-Cox transformations, Fourier representations with time varying coefficients, and ARMA error correction. Likelihood evaluation and analytical expressions for point forecasts and interval predictions under the assumption of Gaussian errors are derived, leading to a simple, comprehensive approach to forecasting complex seasonal time series. A key feature of the framework is that it relies on a new method that greatly reduces the computational burden in the maximum likelihood estimation. The modeling framework is useful for a broad range of applications, its versatility being illustrated in three empirical studies. In addition, the proposed trigonometric formulation is presented as a means of decomposing complex seasonal time series, and it is shown that this decomposition leads to the identification and extraction of seasonal components which are otherwise not apparent in the time series plot itself.},
 author = {Alysha M. De Livera and Rob J. Hyndman and Ralph D. Snyder},
 journal = {Journal of the American Statistical Association},
 number = {496},
 pages = {1513--1527},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Forecasting Time Series With Complex Seasonal Patterns Using Exponential Smoothing},
 volume = {106},
 year = {2011}
}


@article{BergmeirBagging2016,
title = "Bagging exponential smoothing methods using STL decomposition and Box–Cox transformation",
journal = "International Journal of Forecasting",
volume = "32",
number = "2",
pages = "303 - 312",
year = "2016",
issn = "0169-2070",
doi = "https://doi.org/10.1016/j.ijforecast.2015.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0169207015001120",
author = "Christoph Bergmeir and Rob J. Hyndman and José M. Benítez",
keywords = "Bagging, Bootstrapping, Exponential smoothing, STL decomposition",
abstract = "Exponential smoothing is one of the most popular forecasting methods. We present a technique for the bootstrap aggregation (bagging) of exponential smoothing methods, which results in significant improvements in the forecasts. The bagging uses a Box–Cox transformation followed by an STL decomposition to separate the time series into the trend, seasonal part, and remainder. The remainder is then bootstrapped using a moving block bootstrap, and a new series is assembled using this bootstrapped remainder. An ensemble of exponential smoothing models is then estimated on the bootstrapped series, and the resulting point forecasts are combined. We evaluate this new method on the M3 data set, and show that it outperforms the original exponential smoothing models consistently. On the monthly data, we achieve better results than any of the original M3 participants."
}

@ARTICLE{DM1995,
title = {Comparing Predictive Accuracy},
author = {Diebold, Francis and Mariano, Roberto},
year = {1995},
journal = {Journal of Business &amp; Economic Statistics},
volume = {13},
number = {3},
pages = {253-63},
abstract = {The authors propose and evaluate explicit tests of the null hypothesis of no difference in the accuracy of two competing forecasts. In contrast to previously developed tests, a wide variety of accuracy measures can be used (in particular, the loss function need not be quadratic and need not even be symmetric) and forecast errors can be non-Gaussian, nonzero mean, serially correlated, and contemporaneously correlated. Asymptotic and exact finite sample tests are proposed, evaluated, and illustrated.},
url = {https://EconPapers.repec.org/RePEc:bes:jnlbes:v:13:y:1995:i:3:p:253-63}
}


@book{ElementsOfStatisticalLearning,
  author    = {Trevor Hastie and
               Robert Tibshirani and
               Jerome H. Friedman},
  title     = {The elements of statistical learning: data mining, inference, and
               prediction, 2nd Edition},
  series    = {Springer series in statistics},
  publisher = {Springer},
  year      = {2009},
  url       = {http://www.worldcat.org/oclc/300478243},
  isbn      = {9780387848570},
  timestamp = {Wed, 03 May 2017 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/bib/books/lib/HastieTF09},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{ElliotTimmermann2004,
  author={Elliott, Graham and Timmermann, Allan},
  title={{Optimal forecast combinations under general loss functions and forecast error distributions}},
  journal={Journal of Econometrics},
  year=2004,
  volume={122},
  number={1},
  pages={47-79},
  month={September},
  keywords={},
  doi={},
  abstract={Existing results on the properties and performance of forecast combinations have been derived in the context of mean squared error loss. Under this loss function empirical studies have generally found that estimates of optimal forecast combination weights lead to higher losses than equally-weighted combined forecasts which in turn outperform the best individual predictions. We show that this and other results can be overturned when asymmetries are introduced in the loss function and the forecast error distribution is skewed. We characterize the optimal combination weights for the most commonly used alternatives to mean squared error loss and demonstrate how the degree of asymmetry in the loss function and skews in the underlying forecast error distribution can significantly change the optimal combination weights. We also propose estimation methods and investigate their small sample properties in simulations and in an inflation forecasting exercise.<br><small>(This abstract was borrowed from another version of this item.)</small>},
  url={https://ideas.repec.org/a/eee/econom/v122y2004i1p47-79.html}
}


@techreport{SW1998,
 title = "A Comparison of Linear and Nonlinear Univariate Models for Forecasting  Macroeconomic Time Series",
 author = "Stock, James H and Watson, Mark W",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "6607",
 year = "1998",
 month = "June",
 doi = {10.3386/w6607},
 URL = "http://www.nber.org/papers/w6607",
 abstract = {A forecasting comparison is undertaken in which 49 univariate forecasting methods, plus various forecast pooling procedures, are used to forecast 215 U.S. monthly macroeconomic time series at three forecasting horizons over the period 1959 - 1996.  All forecasts simulate real time implementation, that is, they are fully recursive.  The forecasting methods are based on four classes of models: autoregressions (with and without unit root pretests), exponential smoothing, artificial neural networks, and smooth transition autoregressions.  The best overall performance of a single method is achieved by autoregressions with unit root pretests, but this performance can be improved when it is combined with the forecasts from other methods.},
}


@book{breiman1984classification,
  title={Classification and regression trees},
  author={Breiman, Leo and Friedman, Jerome and Stone, Charles J and Olshen, Richard A},
  year={1984},
  publisher={CRC press}
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{friedman2002stochastic,
  title={Stochastic gradient boosting},
  author={Friedman, Jerome H},
  journal={Computational Statistics \& Data Analysis},
  volume={38},
  number={4},
  pages={367--378},
  year={2002},
  publisher={Elsevier}
}


@article{DEUTSCH1994,
title = "The combination of forecasts using changing weights",
journal = "International Journal of Forecasting",
volume = "10",
number = "1",
pages = "47 - 57",
year = "1994",
issn = "0169-2070",
doi = "https://doi.org/10.1016/0169-2070(94)90049-3",
url = "http://www.sciencedirect.com/science/article/pii/0169207094900493",
author = "Melinda Deutsch and Clive W.J. Granger and Timo Teräsvirta",
abstract = "This paper considers the combination of forecasts using changing weights derived from switching regression models or from smooth transition regression models. The regimes associated with the switches may not be known to the forecaster and thus need to be estimated. Several approaches to this problem are considered. In two empirical examples, these time-varying combining procedures produced smaller, in some cases substantially smaller, out-of-sample squared forecast errors than those obtained using the simple linear combining model."
}

@article{DK1996,
author = {Donaldson, R. Glen and Kamstra, Mark},
title = {Forecast combining with neural networks},
journal = {Journal of Forecasting},
volume = {15},
number = {1},
pages = {49-61},
keywords = {forecast combing, artificial neural network, encompassing test},
doi = {10.1002/(SICI)1099-131X(199601)15:1<49::AID-FOR604>3.0.CO;2-2},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-131X%28199601%2915%3A1%3C49%3A%3AAID-FOR604%3E3.0.CO%3B2-2},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/%28SICI%291099-131X%28199601%2915%3A1%3C49%3A%3AAID-FOR604%3E3.0.CO%3B2-2},
abstract = {Abstract This paper investigates the use of Artificial Neural Networks (ANNs) to combine time series forecasts of stock market volatility from the USA, Canada, Japan and the UK. We demonstrate that combining with nonlinear ANNs generally produces forecasts which, on the basis of out-of-sample forecast encompassing tests and mean squared error comparisons, routinely dominate forecasts from traditional linear combining procedures. Superiority of the ANN arises because of its flexibility to account for potentially complex nonlinear relationships not easily captured by traditional linear models.},
year = {1996}
}


@article{DieboldShin2019,
title = "Machine learning for regularized survey forecast combination: Partially-egalitarian LASSO and its derivatives",
journal = "International Journal of Forecasting",
volume = "35",
number = "4",
pages = "1679 - 1691",
year = "2019",
issn = "0169-2070",
doi = "https://doi.org/10.1016/j.ijforecast.2018.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S0169207018301596",
author = "Francis X. Diebold and Minchul Shin",
keywords = "Forecast combination, Forecast surveys, Shrinkage, Model selection, LASSO, Regularization",
abstract = "Despite the clear success of forecast combination in many economic environments, several important issues remain incompletely resolved. The issues relate to the selection of the set of forecasts to combine, and whether some form of additional regularization (e.g., shrinkage) is desirable. Against this background, and also considering the frequently-found good performance of simple-average combinations, we propose a LASSO-based procedure that sets some combining weights to zero and shrinks the survivors toward equality (“partially-egalitarian LASSO”). Ex post analysis reveals that the optimal solution has a very simple form: the vast majority of forecasters should be discarded, and the remainder should be averaged. We therefore propose and explore direct subset-averaging procedures that are motivated by the structure of partially-egalitarian LASSO and the lessons learned, which, unlike LASSO, do not require the choice of a tuning parameter. Intriguingly, in an application to the European Central Bank Survey of Professional Forecasters, our procedures outperform simple average and median forecasts; indeed, they perform approximately as well as the ex post best forecaster."
}

@ARTICLE{Conflitti2015,
title = {Optimal combination of survey forecasts},
author = {Conflitti, Cristina and De Mol, Christine and Giannone, Domenico},
year = {2015},
journal = {International Journal of Forecasting},
volume = {31},
number = {4},
pages = {1096-1103},
abstract = {We consider the problem of combining individual forecasts of real gross domestic product (GDP) growth and Harmonized Index of Consumer Prices (HICP) inflation from the Survey of Professional Forecasters (SPF) for the Euro area. Contrary to the common practice of using equal combination weights, we compute weights which are optimal in the sense that they minimize the mean square forecast error (MSFE) in the case of point forecasts and maximize a logarithmic score in the case of density forecasts. We show that this is a viable strategy even when the number of forecasts to be combined gets large, provided that we constrain these weights to be positive and to sum to one. Indeed, this enforces a form of shrinkage on the weights which ensures a reasonable out-of-sample performance of the combined forecasts.},
keywords = {Forecast combination; Forecast evaluation; Survey of Professional Forecasters; Real-time data; Shrinkage; High-dimensional data;},
url = {https://EconPapers.repec.org/RePEc:eee:intfor:v:31:y:2015:i:4:p:1096-1103}
}


@article{makridakis2018m4,
  title={The M4 Competition: Results, findings, conclusion and way forward},
  author={Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
  journal={International Journal of Forecasting},
  volume={34},
  number={4},
  pages={802--808},
  year={2018},
  publisher={Elsevier}
}